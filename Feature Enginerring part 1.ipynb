{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a65a3b9-1fb5-40c6-b946-a6bc749f5181",
   "metadata": {},
   "source": [
    "# Feature Engineering:\n",
    "## - We are creating new feature from existing features\n",
    "# Fundamental rule  (very very imp)\n",
    "## - ML Alg works with only numbers but not string data\n",
    "## - If we are having string Data then we need to convert into numbers by using Feature Engineering \n",
    "- for that\n",
    "## - Let us apply feature engineering \n",
    "## - convert string data into numberical data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd209df-86b7-4b3d-98e1-32d4cef54d1e",
   "metadata": {},
   "source": [
    "# 1 Feature Engineering \n",
    "- Pre - requistie is  python & Pandas\n",
    "1. Function\n",
    "2. Class\n",
    "3. object \n",
    "4. method\n",
    "5. keyword - args\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb47ccf-acc8-43e9-a36a-d51b034c7e27",
   "metadata": {},
   "source": [
    "## 1 Feature Scaling  (imp )\n",
    "- Feature Scaling is a teachnique to standardize the indepentdent feature present the data in a fixed range\n",
    "- It is preformed during the data pre-processing\n",
    "\n",
    "## 2 Data pre-procossing \n",
    "- In machine learning data pre-processing is an important step\n",
    "- The purpose of the techique is cleaning and organzing the raw data to make is suitsble for building and training machine learning models\n",
    "\n",
    "## 3 Why Data Pre-processing in machine learning \n",
    "- Typically real-world data is incomplete inconsistent , inaccurate (contains errors or outliers) and often lacks specific attribute values/trends\n",
    "- This is where data pre-processing enters the scenario -  helps to clean, format and organize the raw data thereby making it ready to use the data for machine learing models\n",
    "\n",
    "## 4 what type of data we need to handle \n",
    "- Two type of data we need to handle\n",
    "1. Numerical data\n",
    "2. Categorical data\n",
    "\n",
    "## 5 Numerical data\n",
    "- Quantitative data is the maasurement of something monthly sales, or student scores etc.\n",
    "- The natural way to represent these quantites is numerically (e.g 29 students  234689 in sales)\n",
    "- So we need to understand how to transforming raw numberical data into features then we need to use this feature during machine learning\n",
    "\n",
    "## 6 To handle Numerical data \n",
    "- Technique and purpose\n",
    "- label encoder => To convert all character / categorical variable to be numberic\n",
    "- stadardScaler => To Transfrom a feature which is mean to 0 and standard deviation to 1\n",
    "- Transforming Features => We can tranform features\n",
    "- Handling outlier => To handle outlier\n",
    "- Impute missing Values => To impute missing value with strategy\n",
    "\n",
    "## 7 To handle categorical data\n",
    "- Technique and purpose\n",
    "- Encodeing norminal categories => To do one hot encoding\n",
    "- Encodeing ordinal categoriess => Ordinal categorical\n",
    "- Imputing categorical missing values => Imputing categorical missing values with most frequentstrategy\n",
    "\n",
    "## 8 scikit-learn installation \n",
    "- To execute all these example we need to install scikit-learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866ede7e-2949-4fd4-8806-15401b1ba879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc804b-8dbc-48ee-b5c3-64f2c4e9a64d",
   "metadata": {},
   "source": [
    "## 9 lable Encoder\n",
    "- By using this we can convert all character / categorical variable to be numeric\n",
    "\n",
    "## 9.1 LableEncode class\n",
    "- lableEncoder is predefined class in sklearn.preprocessing package\n",
    "- We need to import this class from sklean.preprocessing pakage\n",
    "- Once we imported then we need to create an object o lableEncoder class\n",
    "\n",
    "## 9.2 fit_tranform(p) method\n",
    "- fit_transform(p) is predefined method in LabelEncoder class\n",
    "- We should access this method by using LabelEncoder object only\n",
    "- This method converts categorical variable into numberical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c5bb9d-23b1-49f7-87ad-c7d9d862f2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Compay           Role\n",
      "0   Google   Data science\n",
      "1  Twitter  Sales manager\n",
      "2   Google             HR\n",
      "3  Linkdin             HR\n",
      "\n",
      "    Compay           Role  Compay_n  Role_n\n",
      "0   Google   Data science         0       0\n",
      "1  Twitter  Sales manager         2       2\n",
      "2   Google             HR         0       1\n",
      "3  Linkdin             HR         1       1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "d={\n",
    "    \"Compay\":[\"Google\",\"Twitter\",\"Google\",\"Linkdin\"],\n",
    "    \"Role\":[\"Data science\",\"Sales manager\",\"HR\",\"HR\"]\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(d)\n",
    "\n",
    "print(df)\n",
    "\n",
    "label_encoder=LabelEncoder()\n",
    "\n",
    "df[\"Compay_n\"]=label_encoder.fit_transform(df[\"Compay\"])\n",
    "df[\"Role_n\"]=label_encoder.fit_transform(df[\"Role\"])\n",
    "\n",
    "print()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "713411f0-fa3e-469c-a2eb-6870e3497edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72623689-9031-4520-8746-b51ecabb5099",
   "metadata": {},
   "source": [
    "## 10 MinMaxScaler\n",
    "- Min - max scaling is a common feature pre-processing technique which reults in scaled data values that fall in the range 0 to 1\n",
    "1. 0 is minimum value\n",
    "2. 1 is maximum value\n",
    "- If we rescale the value of numeric feature then it is between two values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fb2928-6527-4668-8a0e-0c72f777e85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x    Y\n",
      "0  10   25\n",
      "1  20   50\n",
      "2  30   75\n",
      "3  40  100\n",
      "4  50  125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d={\n",
    "    \"x\":[10,20,30,40,50],\n",
    "    \"Y\":[25,50,75,100,125]\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(d)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3788450-df7d-4a13-afa7-9f28b76287b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X    Y\n",
      "0  10   25\n",
      "1  20   50\n",
      "2  30   75\n",
      "3  40  100\n",
      "4  50  125\n",
      "\n",
      "[[0.  ]\n",
      " [0.25]\n",
      " [0.5 ]\n",
      " [0.75]\n",
      " [1.  ]]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler: single column\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "d={\n",
    "    \"X\":[10,20,30,40,50],\n",
    "    \"Y\":[25,50,75,100,125]\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(d)\n",
    "mm_scale = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "print(df)\n",
    "\n",
    "one_col = mm_scale.fit_transform(df[[\"X\"]])\n",
    "print()\n",
    "print(one_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f40d62f-26f3-4e85-9d46-47c2a7eb7a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X    Y\n",
      "0  10   25\n",
      "1  20   50\n",
      "2  30   75\n",
      "3  40  100\n",
      "4  50  125\n",
      "\n",
      "[[0.  ]\n",
      " [0.25]\n",
      " [0.5 ]\n",
      " [0.75]\n",
      " [1.  ]]\n",
      "\n",
      "[[0.  ]\n",
      " [0.25]\n",
      " [0.5 ]\n",
      " [0.75]\n",
      " [1.  ]]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler: double column\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "d={\n",
    "    \"X\":[10,20,30,40,50],\n",
    "    \"Y\":[25,50,75,100,125]\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(d)\n",
    "mm_scale = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "print(df)\n",
    "\n",
    "one_col = mm_scale.fit_transform(df[[\"X\"]])\n",
    "two_col= mm_scale.fit_transform(df[[\"Y\"]])\n",
    "print()\n",
    "print(one_col)\n",
    "print()\n",
    "print(two_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eeb95d8a-d345-4055-8e1f-cab09c289640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X    Y\n",
      "0  10   25\n",
      "1  20   50\n",
      "2  30   75\n",
      "3  40  100\n",
      "4  50  125\n",
      "\n",
      "      X     Y\n",
      "0  0.00  0.00\n",
      "1  0.25  0.25\n",
      "2  0.50  0.50\n",
      "3  0.75  0.75\n",
      "4  1.00  1.00\n"
     ]
    }
   ],
   "source": [
    "#MinMaxSclar : two coloumns\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "d={\n",
    "    \"X\":[10,20,30,40,50],\n",
    "    \"Y\":[25,50,75,100,125]\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(d)\n",
    "mm_sclar=MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "print(df)\n",
    "\n",
    "df[[\"X\",\"Y\"]]=mm_sclar.fit_transform(df[[\"X\",\"Y\"]])\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c9349-4a92-4c8a-bd6d-6df49f8d0e0e",
   "metadata": {},
   "source": [
    "## Classes\n",
    "1. LabelEncoder  => fit_transorm()\n",
    "2. MinMaxscaler  => fit_transorm()\n",
    "\n",
    "## 11 Transforming Features\n",
    "- By using Function Tranformer we can Tranform the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1c36c1b-c9c4-4848-b5a2-ab5b0baf05f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 20]\n",
      " [30 40]\n",
      " [50 60]]\n",
      "\n",
      "[[20 30]\n",
      " [40 50]\n",
      " [60 70]]\n"
     ]
    }
   ],
   "source": [
    "# Function Tranformer\n",
    "\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "a=[[10,20],[30,40],[50,60]]\n",
    "f=np.array(a)\n",
    "print(f)\n",
    "\n",
    "def add_ten(x):\n",
    "    return x + 10\n",
    "    \n",
    "obj=FunctionTransformer(add_ten)\n",
    "result=obj.transform(f)\n",
    "\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c5b337-1ef5-4086-880c-a63b97116665",
   "metadata": {},
   "source": [
    "## Handling outlier (very very imp )\n",
    "- Outlier => The value which is very faar from common data it can be small value and large value  eg 10,20,30,40,50 ,100\n",
    "- Outlier means a large value compare with other values\n",
    "- Some values are also out of the range of the feature so they are also considered as outliers\n",
    "- Outlier affect our model's efficieny because it influence the model very much\n",
    "  - Three way to handle these\n",
    "1. Drop outlier of filter outlier\n",
    "2. Making them using boolean condition\n",
    "3. Transform into feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df8b0c0d-16d1-4986-81dd-829ee946792c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    price  room  square_feet\n",
      "0  152331     2         1500\n",
      "1  673888     3         2500\n",
      "2  749990     2         1500\n",
      "3  199034   116       480000\n"
     ]
    }
   ],
   "source": [
    "# A Dataframe with outliers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "house=pd.DataFrame()\n",
    "\n",
    "house['price']=[152331,673888,749990,199034]\n",
    "house['room']=[2,3,2,116]\n",
    "house['square_feet']=[1500,2500,1500,480000]\n",
    "\n",
    "print(house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81027a2a-047f-4a05-a848-0c0b2b79f7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    price  room  square_feet\n",
      "0  152331     2         1500\n",
      "1  673888     3         2500\n",
      "2  749990     2         1500\n"
     ]
    }
   ],
   "source": [
    "# 1. drop outlier of filter outlier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "house=pd.DataFrame()\n",
    "\n",
    "house['price']=[152331,673888,749990,199034]\n",
    "house['room']=[2,3,2,116]\n",
    "house['square_feet']=[1500,2500,1500,480000]\n",
    "\n",
    "con1=house['room']<5\n",
    "new=house[con1]\n",
    "\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fdd344d-0333-429d-91c2-e2c0f5368179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    price  room  square_feet  outlier\n",
      "0  152331     2         1500        0\n",
      "1  673888     3         2500        0\n",
      "2  749990     2         1500        0\n",
      "3  199034   116       480000        1\n"
     ]
    }
   ],
   "source": [
    "# 2 Mark them as outliers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "house=pd.DataFrame()\n",
    "\n",
    "house['price']=[152331,673888,749990,199034]\n",
    "house['room']=[2,3,2,116]\n",
    "house['square_feet']=[1500,2500,1500,480000]\n",
    "\n",
    "house[\"outlier\"]=np.where(house['room']<5,0,1)\n",
    "\n",
    "print(house)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba1f578-1394-4537-86cd-f1a64f5005a5",
   "metadata": {},
   "source": [
    "## 13 Impute / handing Missing values\n",
    "- We can impute missing values with different strategy\n",
    "- These are two types of missing values\n",
    "  1. Numeric missing values\n",
    "  2. Categorical missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a00c56-aec3-4385-8081-05c9fafaf2d3",
   "metadata": {},
   "source": [
    "# 13 impute / handing missing values\n",
    "\n",
    "check the missing values\n",
    "- by using pandas\n",
    "1. df.isna().sum\n",
    "2. df.dropna(p)\n",
    "3. df.fillna(p)\n",
    "4. df.replace(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f2020c-31dd-4a6b-ba02-82782b80eeac",
   "metadata": {},
   "source": [
    "# check the missing values by using feature engineering\n",
    "## 14 Impute missing numberic values\n",
    "- Missing numberic values we can impute with different strategy\n",
    "  1. mean\n",
    "  2. median\n",
    "  3. most_frequent\n",
    "  4. constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5043243-e8f4-43e9-9bef-d5240bd37730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3    NaN      M    average\n",
      "4   70.0      M       good\n",
      "5    NaN   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n"
     ]
    }
   ],
   "source": [
    "# Creating a Dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "students=[\n",
    "    [85,'M','verygood'],\n",
    "    [95,'F','excellent'],\n",
    "    [60,None,'good'],\n",
    "    [None,'M','average'],\n",
    "    [70,'M','good'],\n",
    "    [None,None,'verygood'],\n",
    "    [60,'F','verygood'],\n",
    "    [98,'M','excellent']\n",
    "]\n",
    "\n",
    "cols=['marks','gender','result']\n",
    "df=pd.DataFrame(students , columns=cols)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "691e0e1c-6888-425d-b5f1-74f9bb5e55f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3    NaN      M    average\n",
      "4   70.0      M       good\n",
      "5    NaN   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n",
      "\n",
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3   78.0      M    average\n",
      "4   70.0      M       good\n",
      "5   78.0   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n"
     ]
    }
   ],
   "source": [
    "# Imputing missing numeric values with mean strategy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "students=[\n",
    "    [85,'M','verygood'],\n",
    "    [95,'F','excellent'],\n",
    "    [60,None,'good'],\n",
    "    [None,'M','average'],\n",
    "    [70,'M','good'],\n",
    "    [None,None,'verygood'],\n",
    "    [60,'F','verygood'],\n",
    "    [98,'M','excellent']\n",
    "]\n",
    "\n",
    "cols=['marks','gender','result']\n",
    "df=pd.DataFrame(students , columns=cols)\n",
    "\n",
    "print(df)\n",
    "\n",
    "impute=SimpleImputer(\n",
    "    missing_values=np.nan,\n",
    "    strategy='mean'\n",
    ")\n",
    "\n",
    "result=df['marks'].values.reshape(-1,1)\n",
    "\n",
    "df['marks']=impute.fit_transform(result)\n",
    "\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19794d13-8404-4cc8-b168-7e86941b1721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0641487f-a67a-40c1-99cb-213d00fb5a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    85.0\n",
      "1    95.0\n",
      "2    60.0\n",
      "3     NaN\n",
      "4    70.0\n",
      "5     NaN\n",
      "6    60.0\n",
      "7    98.0\n",
      "Name: marks, dtype: float64\n",
      "\n",
      "[85. 95. 60. nan 70. nan 60. 98.]\n",
      "\n",
      "[[85.]\n",
      " [95.]\n",
      " [60.]\n",
      " [nan]\n",
      " [70.]\n",
      " [nan]\n",
      " [60.]\n",
      " [98.]]\n"
     ]
    }
   ],
   "source": [
    "print(df['marks'])\n",
    "print()\n",
    "print(df['marks'].values)\n",
    "print()\n",
    "print(df['marks'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d45a8a5-d0c0-4a12-bfb8-dc56472be7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3    NaN      M    average\n",
      "4   70.0      M       good\n",
      "5    NaN   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n",
      "\n",
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3   77.5      M    average\n",
      "4   70.0      M       good\n",
      "5   77.5   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n"
     ]
    }
   ],
   "source": [
    "# Imputing missing numeric values with median strategy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "students=[\n",
    "    [85,'M','verygood'],\n",
    "    [95,'F','excellent'],\n",
    "    [60,None,'good'],\n",
    "    [None,'M','average'],\n",
    "    [70,'M','good'],\n",
    "    [None,None,'verygood'],\n",
    "    [60,'F','verygood'],\n",
    "    [98,'M','excellent']\n",
    "]\n",
    "\n",
    "cols=['marks','gender','result']\n",
    "df=pd.DataFrame(students , columns=cols)\n",
    "\n",
    "print(df)\n",
    "\n",
    "impute=SimpleImputer(\n",
    "    missing_values=np.nan,\n",
    "    strategy='median'\n",
    ")\n",
    "\n",
    "result=df['marks'].values.reshape(-1,1)\n",
    "\n",
    "df['marks']=impute.fit_transform(result)\n",
    "\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d7e0736-7300-427c-bef9-f3197c789e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3    NaN      M    average\n",
      "4   70.0      M       good\n",
      "5    NaN   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n",
      "\n",
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3   60.0      M    average\n",
      "4   70.0      M       good\n",
      "5   60.0   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n"
     ]
    }
   ],
   "source": [
    "# Imputing missing numeric values with most_frequent strategy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "students=[\n",
    "    [85,'M','verygood'],\n",
    "    [95,'F','excellent'],\n",
    "    [60,None,'good'],\n",
    "    [None,'M','average'],\n",
    "    [70,'M','good'],\n",
    "    [None,None,'verygood'],\n",
    "    [60,'F','verygood'],\n",
    "    [98,'M','excellent']\n",
    "]\n",
    "\n",
    "cols=['marks','gender','result']\n",
    "df=pd.DataFrame(students , columns=cols)\n",
    "\n",
    "print(df)\n",
    "\n",
    "impute=SimpleImputer(\n",
    "    missing_values=np.nan,\n",
    "    strategy='most_frequent'\n",
    ")\n",
    "\n",
    "result=df['marks'].values.reshape(-1,1)\n",
    "\n",
    "df['marks']=impute.fit_transform(result)\n",
    "\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aabc2ba6-6974-40a6-90e7-02f5627c3bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3    NaN      M    average\n",
      "4   70.0      M       good\n",
      "5    NaN   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n",
      "\n",
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3    0.0      M    average\n",
      "4   70.0      M       good\n",
      "5    0.0   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n"
     ]
    }
   ],
   "source": [
    "# Imputing missing numeric values with constant strategy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "students=[\n",
    "    [85,'M','verygood'],\n",
    "    [95,'F','excellent'],\n",
    "    [60,None,'good'],\n",
    "    [None,'M','average'],\n",
    "    [70,'M','good'],\n",
    "    [None,None,'verygood'],\n",
    "    [60,'F','verygood'],\n",
    "    [98,'M','excellent']\n",
    "]\n",
    "\n",
    "cols=['marks','gender','result']\n",
    "df=pd.DataFrame(students , columns=cols)\n",
    "\n",
    "print(df)\n",
    "\n",
    "impute=SimpleImputer(\n",
    "    missing_values=np.nan,\n",
    "    strategy='constant',\n",
    "\n",
    ")\n",
    "\n",
    "result=df['marks'].values.reshape(-1,1)\n",
    "\n",
    "df['marks']=impute.fit_transform(result)\n",
    "\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90c88d15-0719-4057-845b-55c732ad18cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3    NaN      M    average\n",
      "4   70.0      M       good\n",
      "5    NaN   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n",
      "\n",
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3   80.0      M    average\n",
      "4   70.0      M       good\n",
      "5   80.0   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n"
     ]
    }
   ],
   "source": [
    "# Imputing missing numeric values with constant strategy but fill value with 80\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "students=[\n",
    "    [85,'M','verygood'],\n",
    "    [95,'F','excellent'],\n",
    "    [60,None,'good'],\n",
    "    [None,'M','average'],\n",
    "    [70,'M','good'],\n",
    "    [None,None,'verygood'],\n",
    "    [60,'F','verygood'],\n",
    "    [98,'M','excellent']\n",
    "]\n",
    "\n",
    "cols=['marks','gender','result']\n",
    "df=pd.DataFrame(students , columns=cols)\n",
    "\n",
    "print(df)\n",
    "\n",
    "impute=SimpleImputer(\n",
    "    missing_values=np.nan,\n",
    "    strategy='constant',\n",
    "    fill_value=80\n",
    ")\n",
    "\n",
    "result=df['marks'].values.reshape(-1,1)\n",
    "\n",
    "df['marks']=impute.fit_transform(result)\n",
    "\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9869af6a-e8c4-4e79-bc6a-79a59d4a9c87",
   "metadata": {},
   "source": [
    "# => According to the syntax Simplelmpute object will work with only SINGAL COLUMN ARRAY but not with other data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b95bd3c-7501-4c3e-9f3e-c5384fb7ae65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3    0.0      M    average\n",
      "4   70.0      M       good\n",
      "5    0.0   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n",
      "\n",
      "0    85.0\n",
      "1    95.0\n",
      "2    60.0\n",
      "3     0.0\n",
      "4    70.0\n",
      "5     0.0\n",
      "6    60.0\n",
      "7    98.0\n",
      "Name: marks, dtype: float64\n",
      "\n",
      "[85. 95. 60.  0. 70.  0. 60. 98.]\n",
      "\n",
      "[[85.]\n",
      " [95.]\n",
      " [60.]\n",
      " [ 0.]\n",
      " [70.]\n",
      " [ 0.]\n",
      " [60.]\n",
      " [98.]]\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(df)\n",
    "print()\n",
    "print(df['marks'])\n",
    "print()\n",
    "print(df['marks'].values)\n",
    "print()\n",
    "print(df['marks'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc739b-5918-4c43-adff-a8b2e2490f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
