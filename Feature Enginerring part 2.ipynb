{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4bdadd-a26e-46f7-a564-4ff41bf89bb8",
   "metadata": {},
   "source": [
    "# 1 Handling Categorical Data\n",
    "### Categorical Data\n",
    "- Categorical data are variables that contain label values rather than number values\n",
    "\n",
    "### Types of Categorical data\n",
    "- Nominal variable\n",
    "- Ordinal variable\n",
    "\n",
    "## Nomial Variable\n",
    "- The variables which are having no-order those are called as Nominal variable\n",
    "- Examples:\n",
    "  1. pet variables values : cat,dog\n",
    "  2. color variables values : blue, green , red\n",
    "\n",
    "## Ordinal Variable\n",
    "- The variable which are having an order those are called ordinal Variable\n",
    "- Examples:\n",
    "  1. Score variable values : low,medium,high\n",
    " \n",
    "### Kind note \n",
    "- In real time mostly we do have nominal variable scenarios\n",
    "- So please understand the below scenarios\n",
    "\n",
    "# 2 Encoding Categorical Data\n",
    "- There are 3 ways to convert categorical variable to numerical values\n",
    "  1. Ordinal encoding\n",
    "  2. One hot encoding\n",
    "  3. Dummy variable encoding\n",
    "\n",
    "## 2.1 Ordinal encoding \n",
    "- In ordinal encoding every nominal value is assigned an integer value\n",
    "- Example\n",
    "  1. blue : 0\n",
    "  2. green : 1\n",
    "  3. red : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f1a3313-5a5b-44e6-83c2-215d0597ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['blue']\n",
      " ['green']\n",
      " ['red']]\n"
     ]
    }
   ],
   "source": [
    "# Ordinal encoding\n",
    "\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "a=[['blue'],['green'],['red']]\n",
    "\n",
    "\n",
    "data=asarray(a)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17168da-7279-43e8-a95e-7f499a1e09e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['blue']\n",
      " ['green']\n",
      " ['red']]\n",
      "\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "# Ordinal encoding\n",
    "\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "data=asarray([['blue'],['green'],['red']])\n",
    "\n",
    "print(data)\n",
    "\n",
    "encoder=OrdinalEncoder()\n",
    "result=encoder.fit_transform(data)\n",
    "\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36070818-c627-438b-b649-5fcecc672f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['blue']\n",
      " ['green']\n",
      " ['red']\n",
      " ['orange']]\n",
      "\n",
      "[[0.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "# Ordinal encoding\n",
    "\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "data=asarray([['blue'],['green'],['red'],['orange']])\n",
    "\n",
    "print(data)\n",
    "\n",
    "encoder=OrdinalEncoder()\n",
    "result=encoder.fit_transform(data)  # result=encoder.fit_transform(single column array be have to provide) \n",
    "\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28d6b0-64f9-4bb4-a8df-ec83710e6a51",
   "metadata": {},
   "source": [
    "### Problem with ordinal encoding \n",
    "- If we have applied ordinal encoding on nominal values then it will be an order and having relationship but actually there is no relationship in between the norminal variables\n",
    "- Machine learning algorithm understands like there is an order in between norminal values\n",
    "- So it causes a problem like machine learning algorithm will produce poor performance\n",
    "- We can solve this problem by using one hot encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e63f68-a141-43f7-abad-4573eb0eca6f",
   "metadata": {},
   "source": [
    "## 2.2 One hot encoding\n",
    "- One-hot encoding allows us to turn nominal categoricaldata into feature with numberical values, while not mathenatically implly any ordinal relationship between thr classes.\n",
    "- For nominal values integer encoding may not be enough and even it is misleading the model.\n",
    "- Here one hot encoding helps it is technique where each of the nominal variables will be represented with binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55e32c2a-f73f-4e93-b9f6-2e669e22339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['apply']\n",
      " ['pear']\n",
      " ['apply']\n",
      " ['pear']\n",
      " ['apply']]\n",
      "\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding \n",
    "\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "a=[['apply'],['pear'],['apply'],['pear'],['apply']]\n",
    "data=asarray(a)\n",
    "\n",
    "print(data)\n",
    "\n",
    "encoder=OneHotEncoder(sparse_output=False)\n",
    "onehot=encoder.fit_transform(data)\n",
    "\n",
    "\n",
    "print()\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88560e32-17d3-42bb-9a9e-687eeeec6448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['blue']\n",
      " ['green']\n",
      " ['red']]\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding \n",
    "\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "a=[['blue'],['green'],['red']]\n",
    "data=asarray(a)\n",
    "\n",
    "print(data)\n",
    "\n",
    "encoder=OneHotEncoder(\n",
    "    sparse_output=False\n",
    ")\n",
    "onehot=encoder.fit_transform(data)\n",
    "\n",
    "\n",
    "print()\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa0548-0f15-4acd-a8db-f51f4e37659f",
   "metadata": {},
   "source": [
    "## Dummy variable encoding  (very imp for interview)\n",
    "- The one hot encoding create one binary variable for each category\n",
    "- The problem  is that this representation includes redundancy\n",
    "- For example if we know that [1,0,0] represents for first value and [0,1,0] reprsents for second value then we donot need another binary variable to represent third value , instead we could use ) values alone like [0,0]\n",
    "\n",
    "- One hot encoding example\n",
    "- Example\n",
    "  1. blue:  1 0 0\n",
    "  2. green: 0 1 0\n",
    "  3. red  : 0 0 1\n",
    "\n",
    "- Dummy variable encoding example\n",
    "- Example\n",
    "  1. blue: 0 0\n",
    "  2. Green : 1 0\n",
    "  3. Red : 0 1\n",
    "\n",
    "### Conclusion\n",
    "- If we drop first column from the result of one hot encoding then we will get dummy variable encoding \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12b83473-16e3-46b0-b22c-6c1ffbd35db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['blue']\n",
      " ['green']\n",
      " ['red']]\n",
      "\n",
      "[[0. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Dummy variable encoding  using drop first\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "a=[['blue'],['green'],['red']]\n",
    "data=asarray(a)\n",
    "\n",
    "print(data)\n",
    "\n",
    "encoder=OneHotEncoder(\n",
    "    drop='first',\n",
    "    sparse_output=False\n",
    ")\n",
    "onehot=encoder.fit_transform(data)\n",
    "print()\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d526d8ad-f198-48e5-8b10-23c1bc292828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['blue']\n",
      " ['green']\n",
      " ['red']]\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Dummy variable encoding using drop if_binary\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "a=[['blue'],['green'],['red']]\n",
    "data=asarray(a)\n",
    "\n",
    "print(data)\n",
    "\n",
    "encoder=OneHotEncoder(\n",
    "    drop='if_binary',\n",
    "    sparse_output=False\n",
    ")\n",
    "onehot=encoder.fit_transform(data)\n",
    "print()\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e344ad1f-4d0f-41c0-838f-7a8799ccb00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3    NaN      M    average\n",
      "4   70.0      M       good\n",
      "5    NaN   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "`np.NaN` was removed in the NumPy 2.0 release. Use `np.nan` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(students , columns\u001b[38;5;241m=\u001b[39mcols)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[1;32m     23\u001b[0m impute\u001b[38;5;241m=\u001b[39mSimpleImputer(\n\u001b[0;32m---> 24\u001b[0m     missing_values\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mNaN,\n\u001b[1;32m     25\u001b[0m     strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m result\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/numpy/__init__.py:400\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __expired_attributes__:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` was removed in the NumPy 2.0 release. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__expired_attributes__[attr]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    403\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     )\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchararray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    407\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`np.chararray` is deprecated and will be removed from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe main namespace in the future. Use an array with a string \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor bytes dtype instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: `np.NaN` was removed in the NumPy 2.0 release. Use `np.nan` instead."
     ]
    }
   ],
   "source": [
    "# Imputing missing numeric values with most_frequent strategy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "students=[\n",
    "    [85,'M','verygood'],\n",
    "    [95,'F','excellent'],\n",
    "    [60,None,'good'],\n",
    "    [None,'M','average'],\n",
    "    [70,'M','good'],\n",
    "    [None,None,'verygood'],\n",
    "    [60,'F','verygood'],\n",
    "    [98,'M','excellent']\n",
    "]\n",
    "\n",
    "cols=['marks','gender','result']\n",
    "df=pd.DataFrame(students , columns=cols)\n",
    "\n",
    "print(df)\n",
    "\n",
    "impute=SimpleImputer(\n",
    "    missing_values=np.NaN,\n",
    "    strategy='most_frequent'\n",
    ")\n",
    "\n",
    "result=df['gender'].values.reshape(-1,1)\n",
    "\n",
    "print()\n",
    "print(result)\n",
    "\n",
    "df['gender']=impute.fit_transform(result)\n",
    "\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7e52424-b599-4153-a1ea-78fe3b01aefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DF:\n",
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3    NaN      M    average\n",
      "4   70.0      M       good\n",
      "5    NaN   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n",
      "\n",
      "Gender Before Impute:\n",
      "[['M']\n",
      " ['F']\n",
      " [None]\n",
      " ['M']\n",
      " ['M']\n",
      " [None]\n",
      " ['F']\n",
      " ['M']]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(gender\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Fit & transform\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mfit_transform(gender)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDF After Impute:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[1;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4530\u001b[0m     ):\n\u001b[1;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/frame.py:5267\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m   5266\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m-> 5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n\u001b[1;32m   5275\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   5276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting an Index with object dtype into a DataFrame will stop \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferring another dtype in a future version. Cast the Index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5280\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   5281\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/construction.py:606\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    604\u001b[0m subarr \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m--> 606\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(data)\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    608\u001b[0m         object_index\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_pyarrow_string_dtype()\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_string_dtype(subarr)\n\u001b[1;32m    611\u001b[0m     ):\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;66;03m# Avoid inference when string option is set\u001b[39;00m\n\u001b[1;32m    613\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/dtypes/cast.py:1181\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(value))  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;66;03m# Caller is responsible\u001b[39;00m\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(value\u001b[38;5;241m.\u001b[39mndim)  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[0;31mValueError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "students=[\n",
    "    [85,'M','verygood'],\n",
    "    [95,'F','excellent'],\n",
    "    [60,None,'good'],\n",
    "    [None,'M','average'],\n",
    "    [70,'M','good'],\n",
    "    [None,None,'verygood'],\n",
    "    [60,'F','verygood'],\n",
    "    [98,'M','excellent']\n",
    "]\n",
    "\n",
    "cols=['marks','gender','result']\n",
    "df=pd.DataFrame(students , columns=cols)\n",
    "\n",
    "print(\"Original DF:\")\n",
    "print(df)\n",
    "\n",
    "# Create imputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "# Extract gender column (2D required for sklearn)\n",
    "gender = df[['gender']]\n",
    "\n",
    "print(\"\\nGender Before Impute:\")\n",
    "print(gender.values)\n",
    "\n",
    "# Fit & transform\n",
    "df['gender'] = imputer.fit_transform(gender)\n",
    "\n",
    "print(\"\\nDF After Impute:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "407d52b9-1d01-4ccf-a4db-96a3efbc341c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   marks gender     result\n",
      "0   85.0      M   verygood\n",
      "1   95.0      F  excellent\n",
      "2   60.0   None       good\n",
      "3    NaN      M    average\n",
      "4   70.0      M       good\n",
      "5    NaN   None   verygood\n",
      "6   60.0      F   verygood\n",
      "7   98.0      M  excellent\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "students=[\n",
    "    [85,'M','verygood'],\n",
    "    [95,'F','excellent'],\n",
    "    [60,None,'good'],\n",
    "    [None,'M','average'],\n",
    "    [70,'M','good'],\n",
    "    [None,None,'verygood'],\n",
    "    [60,'F','verygood'],\n",
    "    [98,'M','excellent']\n",
    "]\n",
    "\n",
    "cols=['marks','gender','result']\n",
    "df=pd.DataFrame(students , columns=cols)\n",
    "\n",
    "# Create imputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "gender = df[['gender']]  # keep as 2D\n",
    "\n",
    "# FIX: ravel() to convert 2D -> 1D\n",
    "df['gender'] = imputer.fit_transform(gender).ravel()\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b354b-da08-47d3-8c9e-94be68ac53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
